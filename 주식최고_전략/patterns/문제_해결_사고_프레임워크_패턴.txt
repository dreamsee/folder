문제 해결 사고 프레임워크 패턴

메타 학습: 이번 문제에서 얻은 사고 패턴

문제의 진화 과정
1차 문제 인식: "옐로우카드가 작동 안 함" (표면적 증상)
2차 문제 인식: "17,941개가 잘못 제외됨" (수치적 이상)
3차 문제 인식: "키 매칭 시스템 결함" (구조적 원인)
4차 문제 인식: "고유 식별자 설계 오류" (근본 원인)

사고 전환의 결정적 순간
기존 사고: "수치를 조정해서 맞춰보자"
전환 계기: 사용자 조언 "제외되는 전략들을 먼저 파악해"
새로운 사고: "데이터 패턴을 분석해서 시스템을 이해하자"

5단계 문제 해결 프레임워크

Phase 1: 현상 정확히 기술하기
잘못된 기술: "시스템이 이상해요"
올바른 기술: "17,941개 전략이 제외되는데, 실제 탈락은 2,380개입니다"

핵심 질문들:
- 정확히 무엇이 예상과 다른가?
- 언제부터 이 문제가 시작되었나?
- 어떤 조건에서 발생하는가?
- 영향 범위는 어디까지인가?

Phase 2: 가설 생성과 우선순위
생성된 가설들:
1. 임계값 설정 오류 (낮은 가능성)
2. 데이터 파일 손상 (중간 가능성)  
3. 키 매칭 로직 오류 (높은 가능성) <- 실제 원인
4. 메모리 부족으로 인한 오작동 (낮은 가능성)

가설 평가 기준:
- 재현 가능성
- 증상과의 일치도
- 최근 변경사항과의 연관성

Phase 3: 데이터 기반 검증
가설 검증을 위한 데이터 수집
def verify_hypothesis():
    # 1. 실제 키 생성 과정 추적
    sample_strategies = get_sample_strategies()
    for strategy in sample_strategies:
        key = generate_key(strategy)
        print(f"Strategy: {strategy}")
        print(f"Generated Key: {key}")
    
    # 2. 매칭 과정 시각화
    dropout_keys = load_dropout_keys()
    generated_keys = [generate_key(s) for s in strategies]
    
    # 3. 불일치 패턴 분석
    unmatched = analyze_mismatch_patterns(dropout_keys, generated_keys)
    return unmatched

Phase 4: 구조적 해결책 설계
임시방편 vs 구조적 해결

임시방편: "매칭 임계값을 낮춰서 더 많이 매칭되게 하자"
구조적 해결: "키 생성 로직에 매수전략타입을 포함해서 고유성을 보장하자"

구조적 해결의 특징:
- 근본 원인을 제거
- 향후 유사한 문제 예방
- 시스템 복잡도 감소

Phase 5: 패턴 기반 최적화
문제 해결 + 성능 개선의 통합적 접근

단순 수정: 키 생성 로직만 수정
패턴 기반 개선: 
1. 탈락 패턴 분석 -> 성능이 나쁜 전략 유형 식별
2. 규칙 도출 -> 시가하락(강화), 전일하락(축소), 고무줄매도(제거)
3. 시스템 최적화 -> 340,340개 -> 41,745개 (87.7% 감축)

패턴 인식 기법들

1. 이상 징후 감지 패턴
정상 범위 설정:
- 매칭률: 80-95% (정상)
- 제외율: 5-15% (정상)
- 성능: 기준 대비 ±20% (정상)

이상 징후:
- 매칭률: 0% (심각한 문제)
- 제외율: 50%+ (구조적 문제)
- 성능: 10배 이상 저하 (설계 문제)

2. 데이터 불일치 패턴 분석
def analyze_data_consistency():
    """데이터 불일치 패턴을 체계적으로 분석"""
    
    # 1. 키 형식 분석
    old_keys = ["1_0.5_-2.0_2_3.0", "1_0.3_-5.0_2_4.5"]
    new_keys = ["시가하락_2.0_1_0.5_-2.0_2_3.0", "전일하락_3.0_1_0.3_-5.0_2_4.5"]
    
    # 2. 패턴 매칭 실패 원인 분석
    for old, new in zip(old_keys, new_keys):
        print(f"Old: {old}")
        print(f"New: {new}")
        print(f"Common part: {find_common_part(old, new)}")
    
    # 3. 누락된 정보 식별
    missing_info = identify_missing_components(old_keys, new_keys)
    return missing_info

3. 성능 저하 패턴 분석
def performance_degradation_analysis():
    """성능 저하의 근본 원인 분석"""
    
    # 전략 수 증가 -> 조합 폭발
    strategy_counts = {
        '매수전략': 9,
        '매수수량': 26,
        '손절라인': 17,
        '매도전략': 10
    }
    
    total_combinations = 1
    for key, count in strategy_counts.items():
        total_combinations *= count
        print(f"{key}: {count}개 -> 누적 조합: {total_combinations:,}개")
    
    # 최적화 후 비교
    optimized_counts = {
        '매수전략': 7,     # 9 -> 7 (성능 나쁜 전략 제거)
        '매수수량': 16,    # 26 -> 16 (효과 없는 수량 제거)
        '손절라인': 11,    # 17 -> 11 (극단값 제거)
        '매도전략': 3      # 10 -> 3 (고무줄매도 제거)
    }
    
    optimized_total = 1
    for count in optimized_counts.values():
        optimized_total *= count
    
    improvement = total_combinations / optimized_total
    print(f"개선 효과: {improvement:.1f}배 성능 향상")

창조적 문제 해결 기법

1. 역방향 추론 (Backward Reasoning)
일반적 접근: 문제 -> 원인 -> 해결책
역방향 접근: 이상적 결과 -> 필요조건 -> 현재와의 차이 -> 해결책

예시:
이상적 결과: "모든 탈락 전략이 정확히 매칭되어야 함"
필요조건: "키가 고유해야 함"
현재 문제: "키에 매수전략타입이 없어서 중복 발생"
해결책: "키에 매수전략타입 추가"

2. 제약 조건 완화 (Constraint Relaxation)
원래 제약: "기존 데이터 형식을 유지해야 함"
완화된 제약: "데이터 무결성은 유지하되 형식은 변경 가능"

이를 통해 얻은 해결책:
- 신버전 키 형식 도입
- 구버전과의 호환성 레이어
- 점진적 마이그레이션

3. 아날로지 기법 (Analogy Technique)
문제 상황을 다른 도메인과 비교:

"키 중복 문제" ≈ "주민등록번호 중복 문제"
-> 주민등록번호에 생년월일만 있고 지역코드가 없다면?
-> 같은 날 태어난 사람들이 구분되지 않음
-> 우리 키에도 '매수전략타입'이라는 구분 요소가 필요

이런 아날로지를 통해 해결 방향 직관적 파악 가능

미래 문제 예방 전략

1. 설계 단계에서의 체크리스트
- 고유성 보장: 모든 중요한 구분 요소가 키에 포함되었는가?
- 확장성 고려: 새로운 전략 유형이 추가되어도 키 충돌이 없는가?
- 가독성 유지: 키만 봐도 전략의 특성을 알 수 있는가?
- 성능 고려: 키 생성과 비교 연산이 효율적인가?

2. 모니터링 지표 설정
class SystemHealthMetrics:
    def __init__(self):
        self.thresholds = {
            'key_uniqueness_rate': 0.99,     # 키 고유성 99% 이상
            'matching_success_rate': 0.90,    # 매칭 성공률 90% 이상
            'performance_baseline': 1.0,      # 기준 성능 대비 1배 이내
            'data_consistency_score': 0.95    # 데이터 일관성 95% 이상
        }
    
    def check_system_health(self):
        current_metrics = self.collect_current_metrics()
        alerts = []
        
        for metric, threshold in self.thresholds.items():
            if current_metrics[metric] < threshold:
                alerts.append(f"{metric}: {current_metrics[metric]} < {threshold}")
        
        return alerts

3. 자동화된 회귀 테스트
def regression_test_suite():
    """핵심 기능들이 여전히 작동하는지 확인"""
    
    test_cases = [
        {
            'name': '키_고유성_테스트',
            'input': generate_diverse_strategies(1000),
            'expected': 'all_keys_unique',
            'tolerance': 0.99
        },
        {
            'name': '매칭률_테스트',
            'input': load_sample_dropout_data(),
            'expected': 'matching_rate_above_90_percent',
            'tolerance': 0.90
        }
    ]
    
    for test in test_cases:
        result = execute_test(test)
        assert result >= test['tolerance'], f"Test {test['name']} failed"

학습된 휴리스틱 (경험법칙)

1. 문제 크기 판단법
작은 문제 신호:
- 특정 조건에서만 발생
- 수치 조정으로 해결 가능
- 영향 범위가 제한적

큰 문제 신호:
- 전체 시스템에 영향
- 근본 로직의 오류
- 성능에 심각한 영향
- 데이터 무결성 문제

-> 큰 문제일수록 구조적 접근 필요

2. 우선순위 결정법
긴급도 x 중요도 매트릭스:

High Impact + Urgent: 즉시 해결 (키 매칭 오류)
High Impact + Not Urgent: 계획적 해결 (성능 최적화)
Low Impact + Urgent: 우회법 적용 (UI 버그)
Low Impact + Not Urgent: 나중에 (코드 정리)

3. 해결책 평가 기준
평가 항목별 가중치:
- 문제 해결 완성도: 40%
- 성능 영향: 25%
- 구현 복잡도: 20%
- 유지보수성: 15%

각 해결책을 이 기준으로 점수화해서 최적안 선택

메타 교훈: 문제 해결자의 마음가짐

1. 겸손함의 중요성
"내가 이해했다고 생각한 것도 다시 검증해보자"
-> 키 생성 로직을 안다고 생각했지만, 실제로는 매수전략타입이 빠져있었음

2. 사용자 관점의 가치
개발자 관점: "코드가 논리적으로 맞는데 왜 안 되지?"
사용자 관점: "결과가 이상한데, 뭔가 빠진 게 있는 것 같아"
-> 사용자의 직관적 판단이 때로는 더 정확할 수 있음

3. 데이터를 신뢰하되 맹신하지 않기
데이터가 말해주는 것: "17,941개가 제외되고 있다"
데이터가 말해주지 않는 것: "왜 제외되는가?"
-> 데이터는 현상을 보여주지만, 해석과 통찰은 인간의 몫

핵심 메시지: 
복잡한 문제일수록 서두르지 말고 체계적으로 접근하되, 창조적 사고와 직관도 함께 활용하자. 그리고 가장 중요한 것은 근본 원인을 찾을 때까지 포기하지 않는 끈기이다.

작성일: 2025-08-27  
적용 사례: 옐로우카드 시스템 문제 해결 과정 메타 분석  
활용법: 향후 복잡한 시스템 문제 발생 시 사고 가이드로 활용